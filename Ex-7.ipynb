{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "  words = word_tokenize (text)\n",
    "  # Remove stopwords and punctuation\n",
    "  stop_words = set(stopwords.words('english'))\n",
    "  filtered_words = [word for word in words if word.lower() not in stop_words and word.isalnum()]\n",
    "  # Stemming\n",
    "  stemmer = PorterStemmer()\n",
    "  stemmed_words = [stemmer.stem (word) for word in filtered_words]\n",
    "  return stemmed_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary (text, num_sentences=3):\n",
    "  sentences = sent_tokenize(text)\n",
    "  preprocessed_text = preprocess_text(text)\n",
    "  # Calculate the frequency of each word\n",
    "  word_frequencies = nltk. FreqDist(preprocessed_text)\n",
    "  # Calculate the score for each sentence based on word frequency\n",
    "  sentence_scores = {}\n",
    "  for sentence in sentences:\n",
    "    for word, freq in word_frequencies.items():\n",
    "      if word in sentence.lower():\n",
    "        if sentence not in sentence_scores:\n",
    "          sentence_scores [sentence] = freq\n",
    "        else:\n",
    "          sentence_scores [sentence] += freq\n",
    "  # Select top N sentences with highest scores\n",
    "  summary_sentences = sorted(sentence_scores, key=sentence_scores.get, reverse=True) [:num_sentences]\n",
    "  return''.join(summary_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "\tinput_text =\"\"\"\n",
    "\tNatural language processing (NLP) is a subfield of artificial intelligence.\n",
    "\tIt involves the development of algorithms and models that enact NLP.\n",
    "\tNLP is used in various applications, including chatbots, language Understanding, and language generation.\n",
    "\tThis program demonstrates a simple text summarization using NLP\"\"\"\n",
    "summary = generate_summary(input_text)\n",
    "print(\"Origina1 Text: \")\n",
    "print (input_text )\n",
    "print( \" \\nSummary : \" )\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
